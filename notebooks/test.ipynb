{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /config/.local/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /config/.local/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /config/.local/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /config/.local/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /config/.local/lib/python3.8/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /config/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test7@gmail_com</th>\n",
       "      <th>chhhd</th>\n",
       "      <th>2024-03-11 05:53:14.752370Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>the</td>\n",
       "      <td>2024-03-11 05:54:31.371945Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>value</td>\n",
       "      <td>2024-03-11 05:54:35.228342Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>id</td>\n",
       "      <td>2024-03-11 05:54:35.696709Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>grester</td>\n",
       "      <td>2024-03-11 05:54:37.621267Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>thst</td>\n",
       "      <td>2024-03-11 05:54:38.195503Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>wht</td>\n",
       "      <td>2024-03-11 05:54:39.259525Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>your</td>\n",
       "      <td>2024-03-11 05:54:40.014854Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>thinging</td>\n",
       "      <td>2024-03-11 05:54:42.394930Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>baby</td>\n",
       "      <td>2024-03-11 05:56:39.392282Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>fhrhri</td>\n",
       "      <td>2024-03-11 05:57:15.707415Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>hjis</td>\n",
       "      <td>2024-03-11 05:57:16.691166Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>ieiiei</td>\n",
       "      <td>2024-03-11 05:57:17.755889Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>nsiwooej</td>\n",
       "      <td>2024-03-11 05:57:18.957826Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>nrhri</td>\n",
       "      <td>2024-03-11 05:57:20.026878Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>ehwjsio</td>\n",
       "      <td>2024-03-11 05:57:20.909946Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>nsmajwi</td>\n",
       "      <td>2024-03-11 05:57:22.061389Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test7@gmail_com</td>\n",
       "      <td>uaqic</td>\n",
       "      <td>2024-03-11 05:57:22.924417Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>hfjri</td>\n",
       "      <td>2024-03-11 05:58:56.229124Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>ieir</td>\n",
       "      <td>2024-03-11 05:58:59.458196Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>riod</td>\n",
       "      <td>2024-03-11 05:59:00.528668Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>whst</td>\n",
       "      <td>2024-03-11 05:59:02.159559Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>id</td>\n",
       "      <td>2024-03-11 05:59:02.908341Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>you</td>\n",
       "      <td>2024-03-11 05:59:04.161399Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>hobby</td>\n",
       "      <td>2024-03-11 05:59:06.397208Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>whst</td>\n",
       "      <td>2024-03-11 05:59:07.729672Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>can</td>\n",
       "      <td>2024-03-11 05:59:08.657395Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>be</td>\n",
       "      <td>2024-03-11 05:59:09.063270Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>do</td>\n",
       "      <td>2024-03-11 05:59:09.807750Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>it</td>\n",
       "      <td>2024-03-11 05:59:10.180187Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>for</td>\n",
       "      <td>2024-03-11 05:59:10.715658Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>ig</td>\n",
       "      <td>2024-03-11 05:59:11.210195Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>you</td>\n",
       "      <td>2024-03-11 05:59:12.660181Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>are</td>\n",
       "      <td>2024-03-11 05:59:13.230735Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>by</td>\n",
       "      <td>2024-03-11 05:59:13.679603Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>test@gmail_com</td>\n",
       "      <td>best</td>\n",
       "      <td>2024-03-11 05:59:15.396709Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    test7@gmail_com     chhhd  2024-03-11 05:53:14.752370Z\n",
       "0   test7@gmail_com       the  2024-03-11 05:54:31.371945Z\n",
       "1   test7@gmail_com     value  2024-03-11 05:54:35.228342Z\n",
       "2   test7@gmail_com        id  2024-03-11 05:54:35.696709Z\n",
       "3   test7@gmail_com   grester  2024-03-11 05:54:37.621267Z\n",
       "4   test7@gmail_com      thst  2024-03-11 05:54:38.195503Z\n",
       "5   test7@gmail_com       wht  2024-03-11 05:54:39.259525Z\n",
       "6   test7@gmail_com      your  2024-03-11 05:54:40.014854Z\n",
       "7   test7@gmail_com  thinging  2024-03-11 05:54:42.394930Z\n",
       "8   test7@gmail_com      baby  2024-03-11 05:56:39.392282Z\n",
       "9   test7@gmail_com    fhrhri  2024-03-11 05:57:15.707415Z\n",
       "10  test7@gmail_com      hjis  2024-03-11 05:57:16.691166Z\n",
       "11  test7@gmail_com    ieiiei  2024-03-11 05:57:17.755889Z\n",
       "12  test7@gmail_com  nsiwooej  2024-03-11 05:57:18.957826Z\n",
       "13  test7@gmail_com     nrhri  2024-03-11 05:57:20.026878Z\n",
       "14  test7@gmail_com   ehwjsio  2024-03-11 05:57:20.909946Z\n",
       "15  test7@gmail_com   nsmajwi  2024-03-11 05:57:22.061389Z\n",
       "16  test7@gmail_com     uaqic  2024-03-11 05:57:22.924417Z\n",
       "17   test@gmail_com     hfjri  2024-03-11 05:58:56.229124Z\n",
       "18   test@gmail_com      ieir  2024-03-11 05:58:59.458196Z\n",
       "19   test@gmail_com      riod  2024-03-11 05:59:00.528668Z\n",
       "20   test@gmail_com      whst  2024-03-11 05:59:02.159559Z\n",
       "21   test@gmail_com        id  2024-03-11 05:59:02.908341Z\n",
       "22   test@gmail_com       you  2024-03-11 05:59:04.161399Z\n",
       "23   test@gmail_com     hobby  2024-03-11 05:59:06.397208Z\n",
       "24   test@gmail_com      whst  2024-03-11 05:59:07.729672Z\n",
       "25   test@gmail_com       can  2024-03-11 05:59:08.657395Z\n",
       "26   test@gmail_com        be  2024-03-11 05:59:09.063270Z\n",
       "27   test@gmail_com        do  2024-03-11 05:59:09.807750Z\n",
       "28   test@gmail_com        it  2024-03-11 05:59:10.180187Z\n",
       "29   test@gmail_com       for  2024-03-11 05:59:10.715658Z\n",
       "30   test@gmail_com        ig  2024-03-11 05:59:11.210195Z\n",
       "31   test@gmail_com       you  2024-03-11 05:59:12.660181Z\n",
       "32   test@gmail_com       are  2024-03-11 05:59:13.230735Z\n",
       "33   test@gmail_com        by  2024-03-11 05:59:13.679603Z\n",
       "34   test@gmail_com      best  2024-03-11 05:59:15.396709Z"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.read_csv('firebase_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1861, Test Accuracy: 18.75%\n",
      "Words: khush, maza, hansi, pyaar, anand, khushiyaan\n",
      "\n",
      "Average Predicted Mood: happiness\n",
      "\n",
      "Words: dukhi, udaas, ronaa, gham, malaal, vishad\n",
      "\n",
      "Average Predicted Mood: sadness\n",
      "\n",
      "Words: hangover, bore, tension, stress, boring, sucide\n",
      "\n",
      "Average Predicted Mood: sadness\n",
      "\n",
      "Words: excitement, masti, funnie, hasnaa, maza aaya, majedaar\n",
      "\n",
      "Average Predicted Mood: happiness\n",
      "\n",
      "Words: paagal, lajawab, kasht, dukh, emotional, aansu\n",
      "\n",
      "Average Predicted Mood: sadness\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define the dataset\n",
    "class MoodDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(set(data['words']), start=1)}\n",
    "        self.word_to_idx['<unk>'] = 0  # Add the '<unk>' token with index 0\n",
    "        self.mood_to_idx = {'happiness': 0, 'sadness': 1, 'depression': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.data.iloc[idx]['words']\n",
    "        mood = self.data.iloc[idx]['mood']\n",
    "        return self.word_to_idx.get(word, 0), self.mood_to_idx[mood]\n",
    "\n",
    "# Define the neural network model\n",
    "class MoodClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(MoodClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out = self.fc1(embedded.view(-1, embedded.size(-1)))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_model(data, epochs=100, batch_size=32, lr=0.001, embedding_dim=100, hidden_dim=128):\n",
    "    # Load the dataset\n",
    "    dataset = MoodDataset(data)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Instantiate the model\n",
    "    vocab_size = len(dataset.word_to_idx)\n",
    "    output_dim = len(dataset.mood_to_idx)\n",
    "    model = MoodClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "    # Train the model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for words, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(words)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for words, labels in test_loader:\n",
    "            outputs = model(words)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_moods(model, dataset, word_lists):\n",
    "    mood_to_label = {0: 'happiness', 1: 'sadness', 2: 'depression'}\n",
    "    \n",
    "    for words in word_lists:\n",
    "        word_indices = [dataset.word_to_idx.get(word, 0) for word in words]\n",
    "        inputs = torch.LongTensor(word_indices)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        predicted_moods = [mood_to_label[prediction.item()] for prediction in predicted]\n",
    "        print(f\"Words: {', '.join(words)}\")\n",
    "        \n",
    "        mood_counts = {\n",
    "            'happiness': predicted_moods.count('happiness'),\n",
    "            'sadness': predicted_moods.count('sadness'),\n",
    "            'depression': predicted_moods.count('depression')\n",
    "        }\n",
    "        \n",
    "        average_mood = max(mood_counts, key=mood_counts.get)\n",
    "        print(f\"\\nAverage Predicted Mood: {average_mood}\")\n",
    "        print()\n",
    "\n",
    "# Example usage\n",
    "data = pd.read_csv('hinglish_emotion_dataset.csv')\n",
    "model = train_model(data)\n",
    "dataset = MoodDataset(data)\n",
    "\n",
    "words1 = ['khush', 'maza', 'hansi', 'pyaar', 'anand', 'khushiyaan']\n",
    "words2 = ['dukhi', 'udaas', 'ronaa', 'gham', 'malaal', 'vishad']\n",
    "words3 = ['hangover', 'bore', 'tension', 'stress', 'boring', 'sucide']\n",
    "words4 = ['excitement', 'masti', 'funnie', 'hasnaa', 'maza aaya', 'majedaar']\n",
    "words5 = ['paagal', 'lajawab', 'kasht', 'dukh', 'emotional', 'aansu']\n",
    "\n",
    "word_lists = [words1, words2, words3, words4, words5]\n",
    "\n",
    "predict_moods(model, dataset, word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/config/workspace\n"
     ]
    }
   ],
   "source": [
    "cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriving sepecific person data\n",
    "df ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<firebase_admin.db.Reference object at 0x7fb9dd5b1d30>\n",
      "dict_keys(['test7@gmail_com', 'test@gmail_com'])\n",
      "<firebase_admin.db.Reference object at 0x7fba85298490>\n",
      "{'-Nsg3cEzlXUENlm02AWu': {'timestamp': '2024-03-11 05:53:14.752370Z', 'word': 'chhhd'}, '-Nsg3ux7nCTIldWoTgBi': {'timestamp': '2024-03-11 05:54:31.371945Z', 'word': 'the'}, '-Nsg3vtRQp4G2EKU-smy': {'timestamp': '2024-03-11 05:54:35.228342Z', 'word': 'value'}, '-Nsg3w-khar4i4YEBjzY': {'timestamp': '2024-03-11 05:54:35.696709Z', 'word': 'id'}, '-Nsg3wTpPBQL9Yow538Z': {'timestamp': '2024-03-11 05:54:37.621267Z', 'word': 'grester'}, '-Nsg3wbnZB0p6w6Ie-Lt': {'timestamp': '2024-03-11 05:54:38.195503Z', 'word': 'thst'}, '-Nsg3wsQV6Llk_tVw2cO': {'timestamp': '2024-03-11 05:54:39.259525Z', 'word': 'wht'}, '-Nsg3x3DLp8fWyptCIfr': {'timestamp': '2024-03-11 05:54:40.014854Z', 'word': 'your'}, '-Nsg3xdP8LSjN_tDyqkJ': {'timestamp': '2024-03-11 05:54:42.394930Z', 'word': 'thinging'}, '-Nsg4PCUAgBcvUFGXXCS': {'timestamp': '2024-03-11 05:56:39.392282Z', 'word': 'baby'}, '-Nsg4Y3vZmLEKkKYU4yK': {'timestamp': '2024-03-11 05:57:15.707415Z', 'word': 'fhrhri'}, '-Nsg4YJI-R-IXY2dj9aP': {'timestamp': '2024-03-11 05:57:16.691166Z', 'word': 'hjis'}, '-Nsg4YZvY4KePkTt4HKt': {'timestamp': '2024-03-11 05:57:17.755889Z', 'word': 'ieiiei'}, '-Nsg4YrhbXg-pxZhV_iC': {'timestamp': '2024-03-11 05:57:18.957826Z', 'word': 'nsiwooej'}, '-Nsg4Z7Pg-juuBnHq34v': {'timestamp': '2024-03-11 05:57:20.026878Z', 'word': 'nrhri'}, '-Nsg4ZLCTdrN6nTFE3AR': {'timestamp': '2024-03-11 05:57:20.909946Z', 'word': 'ehwjsio'}, '-Nsg4ZcCpLVzXH8xZjAH': {'timestamp': '2024-03-11 05:57:22.061389Z', 'word': 'nsmajwi'}, '-Nsg4ZpgOJVx7ZPXM0SZ': {'timestamp': '2024-03-11 05:57:22.924417Z', 'word': 'uaqic'}}\n",
      "<firebase_admin.db.Reference object at 0x7fb9de8e4190>\n",
      "{'-Nsg4vbYvbsU0QbAzPdo': {'timestamp': '2024-03-11 05:58:56.229124Z', 'word': 'hfjri'}, '-Nsg4wP1lPTnbIe_vavI': {'timestamp': '2024-03-11 05:58:59.458196Z', 'word': 'ieir'}, '-Nsg4wektBwQrfSsM0ee': {'timestamp': '2024-03-11 05:59:00.528668Z', 'word': 'riod'}, '-Nsg4x3EkdNtTWOKvRdE': {'timestamp': '2024-03-11 05:59:02.159559Z', 'word': 'whst'}, '-Nsg4xEwZrABxhZZS5_7': {'timestamp': '2024-03-11 05:59:02.908341Z', 'word': 'id'}, '-Nsg4xYW-D9JN09cuGN5': {'timestamp': '2024-03-11 05:59:04.161399Z', 'word': 'you'}, '-Nsg4y5SKkE_Jaj34CUy': {'timestamp': '2024-03-11 05:59:06.397208Z', 'word': 'hobby'}, '-Nsg4yQGAKoZeo6lfrPR': {'timestamp': '2024-03-11 05:59:07.729672Z', 'word': 'whst'}, '-Nsg4ydldW3UFe3GznTS': {'timestamp': '2024-03-11 05:59:08.657395Z', 'word': 'can'}, '-Nsg4yk6eJiNtdL9okqo': {'timestamp': '2024-03-11 05:59:09.063270Z', 'word': 'be'}, '-Nsg4yvjjUH8D9SRX3GH': {'timestamp': '2024-03-11 05:59:09.807750Z', 'word': 'do'}, '-Nsg4z0ZfjCxhnt-PzHI': {'timestamp': '2024-03-11 05:59:10.180187Z', 'word': 'it'}, '-Nsg4z8veYqJDiPPdUzm': {'timestamp': '2024-03-11 05:59:10.715658Z', 'word': 'for'}, '-Nsg4zGeaySuOH5EgFSV': {'timestamp': '2024-03-11 05:59:11.210195Z', 'word': 'ig'}, '-Nsg4zcJCV7SBp33hiLE': {'timestamp': '2024-03-11 05:59:12.660181Z', 'word': 'you'}, '-Nsg4zlDvcH_eD18YNIr': {'timestamp': '2024-03-11 05:59:13.230735Z', 'word': 'are'}, '-Nsg4zsEE8SJYCMPtVhT': {'timestamp': '2024-03-11 05:59:13.679603Z', 'word': 'by'}, '-Nsg5-I3woEF6ajhURM-': {'timestamp': '2024-03-11 05:59:15.396709Z', 'word': 'best'}}\n",
      "[{'email': 'test7@gmail_com', 'words': dict_values([{'timestamp': '2024-03-11 05:53:14.752370Z', 'word': 'chhhd'}, {'timestamp': '2024-03-11 05:54:31.371945Z', 'word': 'the'}, {'timestamp': '2024-03-11 05:54:35.228342Z', 'word': 'value'}, {'timestamp': '2024-03-11 05:54:35.696709Z', 'word': 'id'}, {'timestamp': '2024-03-11 05:54:37.621267Z', 'word': 'grester'}, {'timestamp': '2024-03-11 05:54:38.195503Z', 'word': 'thst'}, {'timestamp': '2024-03-11 05:54:39.259525Z', 'word': 'wht'}, {'timestamp': '2024-03-11 05:54:40.014854Z', 'word': 'your'}, {'timestamp': '2024-03-11 05:54:42.394930Z', 'word': 'thinging'}, {'timestamp': '2024-03-11 05:56:39.392282Z', 'word': 'baby'}, {'timestamp': '2024-03-11 05:57:15.707415Z', 'word': 'fhrhri'}, {'timestamp': '2024-03-11 05:57:16.691166Z', 'word': 'hjis'}, {'timestamp': '2024-03-11 05:57:17.755889Z', 'word': 'ieiiei'}, {'timestamp': '2024-03-11 05:57:18.957826Z', 'word': 'nsiwooej'}, {'timestamp': '2024-03-11 05:57:20.026878Z', 'word': 'nrhri'}, {'timestamp': '2024-03-11 05:57:20.909946Z', 'word': 'ehwjsio'}, {'timestamp': '2024-03-11 05:57:22.061389Z', 'word': 'nsmajwi'}, {'timestamp': '2024-03-11 05:57:22.924417Z', 'word': 'uaqic'}])}, {'email': 'test@gmail_com', 'words': dict_values([{'timestamp': '2024-03-11 05:58:56.229124Z', 'word': 'hfjri'}, {'timestamp': '2024-03-11 05:58:59.458196Z', 'word': 'ieir'}, {'timestamp': '2024-03-11 05:59:00.528668Z', 'word': 'riod'}, {'timestamp': '2024-03-11 05:59:02.159559Z', 'word': 'whst'}, {'timestamp': '2024-03-11 05:59:02.908341Z', 'word': 'id'}, {'timestamp': '2024-03-11 05:59:04.161399Z', 'word': 'you'}, {'timestamp': '2024-03-11 05:59:06.397208Z', 'word': 'hobby'}, {'timestamp': '2024-03-11 05:59:07.729672Z', 'word': 'whst'}, {'timestamp': '2024-03-11 05:59:08.657395Z', 'word': 'can'}, {'timestamp': '2024-03-11 05:59:09.063270Z', 'word': 'be'}, {'timestamp': '2024-03-11 05:59:09.807750Z', 'word': 'do'}, {'timestamp': '2024-03-11 05:59:10.180187Z', 'word': 'it'}, {'timestamp': '2024-03-11 05:59:10.715658Z', 'word': 'for'}, {'timestamp': '2024-03-11 05:59:11.210195Z', 'word': 'ig'}, {'timestamp': '2024-03-11 05:59:12.660181Z', 'word': 'you'}, {'timestamp': '2024-03-11 05:59:13.230735Z', 'word': 'are'}, {'timestamp': '2024-03-11 05:59:13.679603Z', 'word': 'by'}, {'timestamp': '2024-03-11 05:59:15.396709Z', 'word': 'best'}])}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, auth, firestore ,db\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Initialize Firebase Admin SDK\n",
    "cred = credentials.Certificate(\"perfectkey-bc35f-firebase-adminsdk-mj5eo-2d903258ae.json\")\n",
    "# firebase_admin.initialize_app(cred, {\n",
    "#     'databaseURL': 'https://perfectkey-bc35f-default-rtdb.firebaseio.com/'\n",
    "# })\n",
    "# Get a reference to the Firebase Realtime Database\n",
    "ref = db.reference()\n",
    "try:\n",
    "   # Get email from query parameters\n",
    "         # Get a reference to the 'users' node\n",
    "       users_ref = ref.child('users')\n",
    "       print(users_ref)\n",
    "\n",
    "    # Initialize an empty list to store user data\n",
    "       user_data = []\n",
    "\n",
    "        # Get all user emails\n",
    "       user_emails = users_ref.get().keys()\n",
    "       \n",
    "       print(user_emails)\n",
    "\n",
    "       email_tst = 'test7@gmail_com'\n",
    "       for email in user_emails:\n",
    "        words_ref = users_ref.child(email).child('words')\n",
    "        print(words_ref)\n",
    "\n",
    "          # Get all words for this user\n",
    "        words_data = words_ref.get()\n",
    "        print(words_data)\n",
    "\n",
    "        \n",
    "          # Append user data to the list\n",
    "        user_data.append({\n",
    "                'email': email,\n",
    "                'words': words_data.values() if words_data else []\n",
    "          })\n",
    "        u_D = pd.DataFrame(user_data)\n",
    "       u_D.head()\n",
    "       print(user_data)\n",
    "\n",
    "except Exception as e:\n",
    "       print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the app code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Test Loss: 0.0616, Test Accuracy: 68.75%\n",
      "Epoch 2/10, Test Loss: 0.0597, Test Accuracy: 68.75%\n",
      "Epoch 3/10, Test Loss: 0.0579, Test Accuracy: 75.00%\n",
      "Epoch 4/10, Test Loss: 0.0564, Test Accuracy: 68.75%\n",
      "Epoch 5/10, Test Loss: 0.0551, Test Accuracy: 68.75%\n",
      "Epoch 6/10, Test Loss: 0.0538, Test Accuracy: 68.75%\n",
      "Epoch 7/10, Test Loss: 0.0528, Test Accuracy: 81.25%\n",
      "Epoch 8/10, Test Loss: 0.0518, Test Accuracy: 81.25%\n",
      "Epoch 9/10, Test Loss: 0.0509, Test Accuracy: 81.25%\n",
      "Epoch 10/10, Test Loss: 0.0500, Test Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import MoodDataset\n",
    "from models import MoodClassifier, train_model, save_model\n",
    "from utils import setup_logging, log_exception\n",
    "\n",
    "def main():\n",
    "    setup_logging()\n",
    "\n",
    "    # Load data\n",
    "    data = pd.read_csv('hinglish_emotion_dataset.csv')\n",
    "    dataset = MoodDataset(data)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Train model\n",
    "    model = MoodClassifier(len(dataset.word_to_idx), 100, 128, 3)\n",
    "    train_model(model, train_loader, test_loader)\n",
    "\n",
    "    # Save model\n",
    "    save_model(model, 'models/mood_classifier.pth')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        log_exception(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-11 05:53:14.752370Z</td>\n",
       "      <td>chhhd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-11 05:54:31.371945Z</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-11 05:54:35.228342Z</td>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-11 05:54:35.696709Z</td>\n",
       "      <td>id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-11 05:54:37.621267Z</td>\n",
       "      <td>grester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-03-11 05:54:38.195503Z</td>\n",
       "      <td>thst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-03-11 05:54:39.259525Z</td>\n",
       "      <td>wht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024-03-11 05:54:40.014854Z</td>\n",
       "      <td>your</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024-03-11 05:54:42.394930Z</td>\n",
       "      <td>thinging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024-03-11 05:56:39.392282Z</td>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024-03-11 05:57:15.707415Z</td>\n",
       "      <td>fhrhri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024-03-11 05:57:16.691166Z</td>\n",
       "      <td>hjis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024-03-11 05:57:17.755889Z</td>\n",
       "      <td>ieiiei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024-03-11 05:57:18.957826Z</td>\n",
       "      <td>nsiwooej</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024-03-11 05:57:20.026878Z</td>\n",
       "      <td>nrhri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024-03-11 05:57:20.909946Z</td>\n",
       "      <td>ehwjsio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024-03-11 05:57:22.061389Z</td>\n",
       "      <td>nsmajwi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024-03-11 05:57:22.924417Z</td>\n",
       "      <td>uaqic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp      word\n",
       "0   2024-03-11 05:53:14.752370Z     chhhd\n",
       "1   2024-03-11 05:54:31.371945Z       the\n",
       "2   2024-03-11 05:54:35.228342Z     value\n",
       "3   2024-03-11 05:54:35.696709Z        id\n",
       "4   2024-03-11 05:54:37.621267Z   grester\n",
       "5   2024-03-11 05:54:38.195503Z      thst\n",
       "6   2024-03-11 05:54:39.259525Z       wht\n",
       "7   2024-03-11 05:54:40.014854Z      your\n",
       "8   2024-03-11 05:54:42.394930Z  thinging\n",
       "9   2024-03-11 05:56:39.392282Z      baby\n",
       "10  2024-03-11 05:57:15.707415Z    fhrhri\n",
       "11  2024-03-11 05:57:16.691166Z      hjis\n",
       "12  2024-03-11 05:57:17.755889Z    ieiiei\n",
       "13  2024-03-11 05:57:18.957826Z  nsiwooej\n",
       "14  2024-03-11 05:57:20.026878Z     nrhri\n",
       "15  2024-03-11 05:57:20.909946Z   ehwjsio\n",
       "16  2024-03-11 05:57:22.061389Z   nsmajwi\n",
       "17  2024-03-11 05:57:22.924417Z     uaqic"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = typed_words('test7@gmail_com')\n",
    "pd.DataFrame(r['words'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials, auth, db\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "cred = credentials.Certificate(\"perfectkey-bc35f-firebase-adminsdk-mj5eo-2d903258ae.json\")\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': 'https://perfectkey-bc35f-default-rtdb.firebaseio.com/'\n",
    "})\n",
    "ref = db.reference()\n",
    "\n",
    "def typed_words1(email):\n",
    "    try:\n",
    "        users_ref = ref.child('users')\n",
    "\n",
    "        # Initialize an empty list to store user data\n",
    "        all_user_data = []\n",
    "\n",
    "        # Get all user emails\n",
    "        all_user_emails = users_ref.get().keys()\n",
    "\n",
    "        for user_email in all_user_emails:\n",
    "            words_ref = users_ref.child(user_email).child('words')\n",
    "            \n",
    "            # Get all words for this user\n",
    "            words_data = words_ref.get()\n",
    "            \n",
    "            # Append user data to the list\n",
    "            all_user_data.append({\n",
    "                'email': user_email,\n",
    "                'words': words_data.values() if words_data else []\n",
    "            })\n",
    "            print(all_user_data)\n",
    "\n",
    "        a_u_d = pd.DataFrame(all_user_data)\n",
    "        print('all_user_data : ________________________________________\\n' )\n",
    "        \n",
    "        # email = request.args.get('email')\n",
    "        print('email___________________\\n' , email)  # Get email from query parameters\n",
    "        row = a_u_d[a_u_d['email'] == email]\n",
    "        print('row __________________________________________________________________\\n' , row)\n",
    "\n",
    "        return render_template('typed_words.html', row=row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'email': 'test7@gmail_com', 'words': dict_values([{'timestamp': '2024-03-11 05:53:14.752370Z', 'word': 'chhhd'}, {'timestamp': '2024-03-11 05:54:31.371945Z', 'word': 'the'}, {'timestamp': '2024-03-11 05:54:35.228342Z', 'word': 'value'}, {'timestamp': '2024-03-11 05:54:35.696709Z', 'word': 'id'}, {'timestamp': '2024-03-11 05:54:37.621267Z', 'word': 'grester'}, {'timestamp': '2024-03-11 05:54:38.195503Z', 'word': 'thst'}, {'timestamp': '2024-03-11 05:54:39.259525Z', 'word': 'wht'}, {'timestamp': '2024-03-11 05:54:40.014854Z', 'word': 'your'}, {'timestamp': '2024-03-11 05:54:42.394930Z', 'word': 'thinging'}, {'timestamp': '2024-03-11 05:56:39.392282Z', 'word': 'baby'}, {'timestamp': '2024-03-11 05:57:15.707415Z', 'word': 'fhrhri'}, {'timestamp': '2024-03-11 05:57:16.691166Z', 'word': 'hjis'}, {'timestamp': '2024-03-11 05:57:17.755889Z', 'word': 'ieiiei'}, {'timestamp': '2024-03-11 05:57:18.957826Z', 'word': 'nsiwooej'}, {'timestamp': '2024-03-11 05:57:20.026878Z', 'word': 'nrhri'}, {'timestamp': '2024-03-11 05:57:20.909946Z', 'word': 'ehwjsio'}, {'timestamp': '2024-03-11 05:57:22.061389Z', 'word': 'nsmajwi'}, {'timestamp': '2024-03-11 05:57:22.924417Z', 'word': 'uaqic'}])}]\n",
      "[{'email': 'test7@gmail_com', 'words': dict_values([{'timestamp': '2024-03-11 05:53:14.752370Z', 'word': 'chhhd'}, {'timestamp': '2024-03-11 05:54:31.371945Z', 'word': 'the'}, {'timestamp': '2024-03-11 05:54:35.228342Z', 'word': 'value'}, {'timestamp': '2024-03-11 05:54:35.696709Z', 'word': 'id'}, {'timestamp': '2024-03-11 05:54:37.621267Z', 'word': 'grester'}, {'timestamp': '2024-03-11 05:54:38.195503Z', 'word': 'thst'}, {'timestamp': '2024-03-11 05:54:39.259525Z', 'word': 'wht'}, {'timestamp': '2024-03-11 05:54:40.014854Z', 'word': 'your'}, {'timestamp': '2024-03-11 05:54:42.394930Z', 'word': 'thinging'}, {'timestamp': '2024-03-11 05:56:39.392282Z', 'word': 'baby'}, {'timestamp': '2024-03-11 05:57:15.707415Z', 'word': 'fhrhri'}, {'timestamp': '2024-03-11 05:57:16.691166Z', 'word': 'hjis'}, {'timestamp': '2024-03-11 05:57:17.755889Z', 'word': 'ieiiei'}, {'timestamp': '2024-03-11 05:57:18.957826Z', 'word': 'nsiwooej'}, {'timestamp': '2024-03-11 05:57:20.026878Z', 'word': 'nrhri'}, {'timestamp': '2024-03-11 05:57:20.909946Z', 'word': 'ehwjsio'}, {'timestamp': '2024-03-11 05:57:22.061389Z', 'word': 'nsmajwi'}, {'timestamp': '2024-03-11 05:57:22.924417Z', 'word': 'uaqic'}])}, {'email': 'test@gmail_com', 'words': dict_values([{'timestamp': '2024-03-11 05:58:56.229124Z', 'word': 'hfjri'}, {'timestamp': '2024-03-11 05:58:59.458196Z', 'word': 'ieir'}, {'timestamp': '2024-03-11 05:59:00.528668Z', 'word': 'riod'}, {'timestamp': '2024-03-11 05:59:02.159559Z', 'word': 'whst'}, {'timestamp': '2024-03-11 05:59:02.908341Z', 'word': 'id'}, {'timestamp': '2024-03-11 05:59:04.161399Z', 'word': 'you'}, {'timestamp': '2024-03-11 05:59:06.397208Z', 'word': 'hobby'}, {'timestamp': '2024-03-11 05:59:07.729672Z', 'word': 'whst'}, {'timestamp': '2024-03-11 05:59:08.657395Z', 'word': 'can'}, {'timestamp': '2024-03-11 05:59:09.063270Z', 'word': 'be'}, {'timestamp': '2024-03-11 05:59:09.807750Z', 'word': 'do'}, {'timestamp': '2024-03-11 05:59:10.180187Z', 'word': 'it'}, {'timestamp': '2024-03-11 05:59:10.715658Z', 'word': 'for'}, {'timestamp': '2024-03-11 05:59:11.210195Z', 'word': 'ig'}, {'timestamp': '2024-03-11 05:59:12.660181Z', 'word': 'you'}, {'timestamp': '2024-03-11 05:59:13.230735Z', 'word': 'are'}, {'timestamp': '2024-03-11 05:59:13.679603Z', 'word': 'by'}, {'timestamp': '2024-03-11 05:59:15.396709Z', 'word': 'best'}])}]\n",
      "all_user_data : ________________________________________\n",
      "\n",
      "Working outside of request context.\n",
      "\n",
      "This typically means that you attempted to use functionality that needed\n",
      "an active HTTP request. Consult the documentation on testing for\n",
      "information about how to avoid this problem.\n"
     ]
    }
   ],
   "source": [
    "h = typed_words1(email)\n",
    "h = pd.DataFrame(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m email \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest@gmail_com\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memail\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m email]\n\u001b[1;32m      3\u001b[0m col \u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m col \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(col)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "email = 'test@gmail_com'\n",
    "row = df[df['email'] == email]\n",
    "col =row['words'].iloc[0]\n",
    "col = pd.DataFrame(col)\n",
    "col.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/config/workspace\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modular function to retrive data of specific email from firebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typed_words(email):\n",
    "  try:\n",
    "            users_ref = ref.child('users')\n",
    "\n",
    "            # Initialize an empty list to store user data\n",
    "            all_user_data = []\n",
    "\n",
    "              # Get all user emails\n",
    "            all_user_emails = users_ref.get().keys()\n",
    "            \n",
    "            print(all_user_emails)\n",
    "\n",
    "            for user_email in all_user_emails:\n",
    "                  words_ref = users_ref.child(user_email).child('words')\n",
    "                  print(words_ref)\n",
    "\n",
    "                    # Get all words for this user\n",
    "                  words_data = words_ref.get()\n",
    "                  # print(words_data)\n",
    "\n",
    "                  \n",
    "                    # Append user data to the list\n",
    "                  all_user_data.append({\n",
    "                          'email': user_email,\n",
    "                          'words': words_data.values() if words_data else []\n",
    "                    })\n",
    "\n",
    "            all_user_data = pd.DataFrame(all_user_data)\n",
    "            print(all_user_data)\n",
    "            email = email.replace('.', '_')\n",
    "            row = all_user_data[all_user_data['email'] == email]\n",
    "            return row\n",
    "      \n",
    "      #  print(user_data)\n",
    "\n",
    "  except Exception as e:\n",
    "       print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mood Analyzer Class\n",
    "class MoodAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        print('data')\n",
    "\n",
    "    def analyze_mood(self):\n",
    "        model = train_model(self.data)\n",
    "        print('model')\n",
    "        word_lists = [self.data['word'].iloc[i].split() for i in range(len(self.data))]\n",
    "        print('word_lists')\n",
    "        print(word_lists)\n",
    "        predicted_moods = predict_moods(model, self.data, word_lists)\n",
    "        print('1')\n",
    "        return predicted_moods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define the dataset\n",
    "class MoodDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(set(data['words']), start=1)}\n",
    "        self.word_to_idx['<unk>'] = 0  # Add the '<unk>' token with index 0\n",
    "        self.mood_to_idx = {'happiness': 0, 'sadness': 1, 'depression': 2}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        word = self.data.iloc[idx]['words']\n",
    "        mood = self.data.iloc[idx]['mood']\n",
    "        print('7')\n",
    "        return self.word_to_idx.get(word, 0), self.mood_to_idx[mood]\n",
    "\n",
    "# Define the neural network model\n",
    "class MoodClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(MoodClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        out = self.fc1(embedded.view(-1, embedded.size(-1)))\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "def train_model(data, epochs=100, batch_size=32, lr=0.001, embedding_dim=100, hidden_dim=128):\n",
    "    # Load the dataset\n",
    "    dataset = MoodDataset(data)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print('8')\n",
    "\n",
    "    # Instantiate the model\n",
    "    vocab_size = len(dataset.word_to_idx)\n",
    "    output_dim = len(dataset.mood_to_idx)\n",
    "    model = MoodClassifier(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "    # Train the model\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for words, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(words)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for words, labels in test_loader:\n",
    "            outputs = model(words)\n",
    "            test_loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100 * correct / len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict_moods(model, dataset, word_lists):\n",
    "    print('predicit_moods')\n",
    "    mood_to_label = {0: 'happiness', 1: 'sadness', 2: 'depression'}\n",
    "    \n",
    "    for words in word_lists:\n",
    "        word_indices = [dataset.word_to_idx.get(word, 0) for word in words]\n",
    "        inputs = torch.LongTensor(word_indices)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        predicted_moods = [mood_to_label[prediction.item()] for prediction in predicted]\n",
    "        print(f\"Words: {', '.join(words)}\")\n",
    "        \n",
    "        mood_counts = {\n",
    "            'happiness': predicted_moods.count('happiness'),\n",
    "            'sadness': predicted_moods.count('sadness'),\n",
    "            'depression': predicted_moods.count('depression')\n",
    "        }\n",
    "        \n",
    "        average_mood = max(mood_counts, key=mood_counts.get)\n",
    "        print(f\"\\nAverage Predicted Mood: {average_mood}\")\n",
    "        print()\n",
    "\n",
    "        \n",
    "\n",
    "# # Example usage\n",
    "# data = pd.read_csv('hinglish_emotion_dataset.csv')\n",
    "# model = train_model(data)\n",
    "\n",
    "# words1 = ['khush', 'maza', 'hansi', 'pyaar', 'anand', 'khushiyaan']\n",
    "# words2 = ['dukhi', 'udaas', 'ronaa', 'gham', 'malaal', 'vishad']\n",
    "# words3 = ['hangover', 'bore', 'tension', 'stress', 'boring', 'sucide']\n",
    "# words4 = ['excitement', 'masti', 'funnie', 'hasnaa', 'maza aaya', 'majedaar']\n",
    "# words5 = ['paagal', 'lajawab', 'kasht', 'dukh', 'emotional', 'aansu']\n",
    "\n",
    "# word_lists = [words1, words2, words3, words4, words5]\n",
    "\n",
    "# dataset = MoodDataset(data)\n",
    "# predict_moods(model, dataset, word_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
